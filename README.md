# SynCED-EnDe â€” Pipeline, Raw Data & Scripts (GitHub Companion)

This repository provides **pipeline scripts and raw/intermediate files** for building the
[SynCED-EnDe dataset](https://huggingface.co/datasets/moon712/SynCED_EnDe_2025).

The **clean, benchmark-ready release** (train silver + eval gold) is on Hugging Face.  
This repo is for **reproducibility and transparency**.

---

## ğŸ“‚ Repository Structure

```
scripts/                 # Core dataset creation pipeline
  labels.py                 # compute label distributions and schema
  inject.py                 # inject controlled errors
  reinject.py               # retry injection for missing cases
  skim.py                   # preview dataset (sanity check)
  block_evalrows.py         # filter out evaluation rows
  final.py                  # assemble final dataset TSVs

extras/                  # Helper & debug scripts
  data_check.py             # sanity checks (counts, distributions)
  data_scrape.py            # (if shareable) source scraping
  train_data/               # legacy scripts
    check.py
    master.py

data/                    # Raw & intermediate data files
  train-silver/raw/...
  eval-gold/raw/...

docs/
  annotation_protocol.pdf   # annotation guidelines
  labels.json               # schema for labels
```

---

## ğŸ› ï¸ Pipeline Usage

Run the scripts in **order**:

1. **Define labels**
   ```bash
   python scripts/labels.py
   ```

2. **Inject errors (first pass)**
   ```bash
   python scripts/inject.py
   ```

3. **Re-inject (fix empty rows, optional second pass)**
   ```bash
   python scripts/reinject.py
   ```

4. **Preview dataset (skim head rows)**
   ```bash
   python scripts/skim.py
   ```

5. **Block evaluation rows (avoid leakage)**
   ```bash
   python scripts/block_evalrows.py
   ```

6. **Assemble final dataset**
   ```bash
   python scripts/final.py
   ```
   This produces:
   - `synced_ende_train_silver.tsv`
   - `synced_ende_eval_gold.tsv`
   - `judged_quantified_annotated.tsv`

---

## ğŸ“Š Raw / Intermediate Data

Available in `data/`:
- `ced_final_injected_multi_class.tsv`
- `error_injected_rows_with_correctMT.tsv`
- `rows_for_error_injection.tsv`
- `sources_2024_2025.tsv`

âš ï¸ **Note:** These files may contain earlier/unverified labels.  
They are **not for benchmarking** â€” use only for reproducing pipeline steps.

---

## ğŸ“˜ Documentation
- `docs/annotation_protocol.pdf` â†’ annotation guidelines  
- `docs/labels.json` â†’ schema for binary, multi-class, and 5-dimension ratings  

---

## ğŸ§ª Baselines (BERT / XLMâ€‘R / ModernBERT)

This repo includes simple **text-classification baselines** to assess SynCEDâ€‘EnDe.
All models treat CED as **binary classification** over the pair *(src_en, mt_de)*.

### Setup
- Python â‰¥ 3.9
- Install deps:
  ```bash
  pip install -U torch transformers datasets scikit-learn evaluate accelerate
  ```
- Expected columns in TSV: `rid, src_en, mt_de, target_err` (labels are strings `ERR`/`NOT`).

### Data Feeding (pair encoding)
Each baseline concatenates **source + translation** via the tokenizerâ€™s
`text` / `text_pair` (i.e., `tokenizer(src_en, text_pair=mt_de, ...)`).

### Run: XLMâ€‘R (recommended crossâ€‘lingual baseline)
```bash
python scripts/baselines/baseline_xlmr.py \
  --model_name xlm-roberta-base \
  --train_path train-silver/synced_ende_train_silver.tsv \
  --eval_path  eval-gold/synced_ende_eval_gold.tsv \
  --text_cols src_en mt_de \
  --label_col target_err \
  --epochs 3 --batch_size 16 --lr 2e-5 --seed 13 \
  --max_length 256 \
  --output_dir runs/xlmr_base
```

### Run: BERTâ€‘base (monolingual sanity baseline)
```bash
python scripts/baselines/baseline_bert.py \
  --model_name bert-base-uncased \
  --train_path train-silver/synced_ende_train_silver.tsv \
  --eval_path  eval-gold/synced_ende_eval_gold.tsv \
  --text_cols src_en mt_de \
  --label_col target_err \
  --epochs 3 --batch_size 16 --lr 2e-5 --seed 13 \
  --max_length 256 \
  --output_dir runs/bert_base
```

### Run: ModernBERT (optional)
```bash
python scripts/baselines/baseline_modernbert.py \
  --model_name <modernbert-model-id> \
  --train_path train-silver/synced_ende_train_silver.tsv \
  --eval_path  eval-gold/synced_ende_eval_gold.tsv \
  --text_cols src_en mt_de \
  --label_col target_err \
  --epochs 3 --batch_size 16 --lr 2e-5 --seed 13 \
  --max_length 256 \
  --output_dir runs/modernbert
```

### Metrics & Outputs
Each baseline script prints and saves:
- **MCC**, **F1â€‘ERR**, **F1â€‘NOT**, **Macroâ€‘F1**, **Accuracy**
- `runs/<exp>/metrics.json` with all metrics
- (optional) `runs/<exp>/confusion_matrix.png`

### Tips
- Longer sentences: bump `--max_length 384` (cost â†‘).
- Repro: always set `--seed` and `--gradient_accumulation_steps` if using small GPUs.

---

## ğŸ“œ License
This dataset and accompanying scripts are licensed under:  
**Creative Commons Attribution-NonCommercial 4.0 (CC-BY-NC 4.0)**  
Non-commercial use only, attribution required.  
<https://creativecommons.org/licenses/by-nc/4.0/>

---

## ğŸ“– Citation
```
Chopra, Muskaan, et al. "SynCED-EnDe: A Goldâ€“Silver Dataset for Critical Error Detection in Englishâ†’German MT." 2025.
Hugging Face Datasets: https://huggingface.co/datasets/your-username/synced-ende
```

